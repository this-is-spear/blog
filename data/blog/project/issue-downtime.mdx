---
title: 배포중 무중단 서비로 개선
date: '2024-09-13'
tags: ['프로젝트', '회고']
draft: false
summary: 유레카 이용시 배포 다운타임 존재하는 상황
images: []
---

<TOCInline toc={props.toc} exclude="Introduction" />

# 상황

서비스 배포시 다운타임 8분간 지속되는 상황을 겪었다.

# 문제

서비스 교체시 다운타임 존재했고, 교체 중 사용자 요청을 정상 처리할 수 없는 문제가 발생했다.

### 배포시 다운타임이 발생한다.

게이트웨이 레지스트리에서 존재하는 서비스 상태와 실제 서비스 상태보다 늦게 업데이트 돼 발생한다.
유레카를 이용하면 로드 밸런싱할 경로가 캐시 TTL만큼 다운타임이 발생한다.
로드 밸런싱할 경로 캐시 TTL은 기본 값이 30초로 업데이트가 즉각적으로 반영되지 않는다.

### 다운타임이 예상보다 오래 지속된다.

배포는 서비스 시작과 종료를 순차적으로 수행되고 있다.
다운타임은 `인스턴스 개수 * 30s` 까지 발생해야 하는데 그 이상 유지되고 있다.

# 원인

### 배포시 다운타임이 발생하는 문제 원인

유레카 서버는 즉각적으로 정보를 갱신하지만  Gateway에서 30초 간격으로 갱신하기 때문에 최장 30초까지 다운타임이 발생한다.

![그림 1](/static/images/project/issue-downtime/1.png)

해당 다운타임은 서비스 인스턴스에 비례하기도 한다. 간단하게 아래 상황의 영향도가 존재한다.

- 서비스 시작과 종료를 순차적으로 수행한다면 서비스 다운타임은 `인스턴스 개수 * 30s` 까지 발생
- 서비스 시작과 종료를 동시에 수행한다면 서비스 영향도는 `인스턴스 개수 * N 회`만큼 증가

서비스 시작과 종료를 순차적으로 수행한다면 서비스 다운타임은 `인스턴스 개수 * 30s` 까지 발생할 수 있다.

![그림 2](/static/images/project/issue-downtime/2.png)

서비스 시작과 종료를 동시에 수행한다면 서비스 다운타임 시간을 줄일 수 있지만 서비스 영향도는 `인스턴스 개수 * N 회`만큼 증가하게 된다.

![그림 3](/static/images/project/issue-downtime/3.png)

### 다운타임이 예상시간보다 오래 지속되는 원인

기능 추가가 늘어나면서 애플리케이션 컨텍스트가 올라가는 시간 증가하면서 컨텍스트가 뜨기 전에 health check 날리는게 원인이다.

![그림 4](/static/images/project/issue-downtime/4.png)

유레카 서버 로그에서는 인스턴스가 새로 생성되고 종료됨이 반복되며 다운타임 영향도와 간격이 길어졌다.
생성 종료가 반복되는 현상을 인프라팀과 이야기를 나눴고, ecs에서 일정 시간동안 health check가 되지 않으면 재시작함을 알게 됐다.

# 해결

### 배포시 다운타임이 발생하는 현상 해결

다운타임 현상 해결 방법은 두 가지로 정의할 수 있다.

- 유레카 서버와 유레카 클라이언트 간 레지스트리 `sync`를 맞춘다.
- 배포 과정에서 유레카 클라이언트 등록 해제(`unregister`)를 서비스 종료 시점보다 빠르게 잡는다.

**해결 방안 1 : 유레카 서버와 유레카 클라이언트 간 레지스트리 `sync`를 맞춘다.**

첫 번째 해결방안은 레지스트리 TTL을 짧게 잡고 TTL동안 `sync`가 맞지 않아 실패하는 요청을 재시도하는 방식이다.

![그림 5](/static/images/project/issue-downtime/5.png)

그 과정에서 레지스트리 갱신하기 위한 데이터 비교가 이루어지는데, 갱신된 데이터 만 받아 응답 데이터 양을 줄일 수도 있다.

설정할 옵션은 다음과 같다.

- eureka.client.registry-fetch-interval-seconds=5s
- eureka.client.disable-delta=true

```yaml
  hello-gateway:
    build: ./hello-gateway
    deploy:
      replicas: 2
    ports:
      - "8080-8081:8080"
    environment:
	      # fetching 타임을 줄여 런타임에 실시간으로 변경된 정보를 가져온다.
      - eureka.client.registry-fetch-interval-seconds=5
	     # 유레카에서 변경되는 정보만 가져온다. See EurekaClientConfigBean 페치 사이클 변경에 쉽게 대응할 수 있다.
      - eureka.client.disable-delta=true
      - spring.cloud.gateway.httpclient.connect-timeout=10000
      - spring.cloud.gateway.httpclient.response-timeout=5s
```

이 과정에 큰 문제는 `connection timeout` 제어가 힘들어진다는 점이다. 커넥션 연결을 시도하다 서비스가 내려가면 사용자는 최대 30초까지 대기해야 한다. 이런 문제를 해결하기 위해 httpclient 요청에 대한 `connection timeout` 설정이 가능하다.

```yaml
  hello-gateway:
    build: ./hello-gateway
    deploy:
      replicas: 2
    ports:
      - "8080-8081:8080"
    environment:
	    # fetching 타임을 줄여 런타임에 실시간으로 변경된 정보를 가져온다.
      - eureka.client.registry-fetch-interval-seconds=5
	    # 유레카에서 변경되는 정보만 가져온다. See EurekaClientConfigBean 페치 사이클 변경에 쉽게 대응할 수 있다.
      - eureka.client.disable-delta=true
      # http client로 커넥션 맺어질 때 connection timeout 설정
      - spring.cloud.gateway.httpclient.connect-timeout=5000
```
이후 게이트웨이에서 INTERNAL_SERVER_ERROR 에러 대해서 retry를 수행한다. 게이트웨이 API `RetryGatewayFilterFactory`에서 아래 정보를 모아 필터를 수행해준다.

```kotlin
	@Override
	public List<String> shortcutFieldOrder() {
		return Arrays.asList("retries", "statuses", "methods", "backoff.firstBackoff", "backoff.maxBackoff",
				"backoff.factor", "backoff.basedOnPreviousValue");
	}
```

`yaml` 파일에서는 다음처럼 설정하면 된다.

```yaml
    filters:
      - name: Retry
        args:
          retries: 3
          statuses: INTERNAL_SERVER_ERROR
          methods: *
          backoff:
            firstBackoff: 10ms
            maxBackoff: 50ms
            factor: 2
            basedOnPreviousValue: false
```

아쉽게도 해당 방식은 `connection timeout`이 발생하면 해당 사용자는 5초 정도 대기해야 한다. 만약 1초 내외로 줄이고 싶다면 `connection timeout` 을 더욱 짧게 잡아야해서 `connection timeout` 에 대한 의도치 않은 제약이 걸리게 된다.

그래서 `connection timeout` 설정을 변경하지 않는 방법을 활용했다.

**해결방안 2 : actuator 활용해 배포 프로세스를 개선한다.**

두 번째 해결 방법은 actuator를 활용해 유레카 서버 등록-해제를 제어하는 방법이다. 즉, 서비스 종료 전에 서비스 해제 API를 사용해 미리 유레카 서버에서 등록 해제한다.

![그림 6](/static/images/project/issue-downtime/6.png)

spring actuator는 service registry 동작을 제어하는 인터페이스를 제공하고 spring cloud comons 은 해당 인터페이스의 구현체가 담겨있다. 내용은 다음과 같다.


> Service Registry Actuator Endpoint
> Spring Cloud Commons provides a `/serviceregistry`actuator endpoint.
> This endpoint relies on a`Registration`bean in the Spring Application Context.
> Calling`/serviceregistry`with GET returns the status of the`Registration`.
> Using POST to the same endpoint with a JSON body changes the status of the current`Registration`to the new value.
> The JSON body has to include the`status`field with the preferred value.
> Please see the documentation of the`ServiceRegistry`implementation you use for the allowed values when updating the status and the values returned for the status.
For instance, Eureka’s supported statuses are`UP`,`DOWN`,`OUT_OF_SERVICE`, and`UNKNOWN`.

다음처럼 GET 요청을 보내면 현재 상태 확인이 가능하다.

```
GET /actuator/serviceregistry

{
    "overriddenStatus": "UP",
    "status": "UP"
}
```

다음처럼 POST 요청을 보내면 상태 변경이 가능하다.

```
POST /actuator/serviceregistry

{ "status": "DOWN" }
```

해당 방식은 유레카 서버에게 즉각적인 상태 반영은 가능하지만 서비스 상태와 달라 sync 맞추기가 어렵다.
만약 `spring actuator`가 제공하는 `health check`와 유레카 서버 상태 간 sync를 맞추려면 다음 방법이 좋다.

**해결방안 3 : health check 와 eureka staus 간 sync 를 맞춘다.**

유레카 서버는 `eureka.client.healthcheck.enabled: true` 로 설정되면 서비스 상태로 유레카 서버 등록 해제를 제어한다.
서비스 상태가 `OUT-OF-SERVICE`나 `DOWN`이면 유레카는 서비스 상태를 캐치해 등록 해제를 진핸한다.

`eureka.client.healthcheck.enabled=true` 설정과 함께 다음 **헬스체크 핸들러 구현**이 필요하다.

```java
package com.netflix.appinfo;

/**
 * This provides a more granular healthcheck contract than the existing {@link HealthCheckCallback}
 *
 * @author Nitesh Kant
 */
public interface HealthCheckHandler {

    InstanceInfo.InstanceStatus getStatus(InstanceInfo.InstanceStatus currentStatus);

}
```

> 꼭 package com.netflix.appinfo 패키지에 있는 HealthCheckHandler를 구현해야 한다. 그렇지 않으면 spring actuator만 인식해 유레카 서버에 의도한 동작이 안먹힐 수 있다.
> spring actuator 동작으로 health 상태를 `OUT_OF_SERVICE`로 변경한다면 유레카는 이를 감지해 강제로 `DOWN`으로 낮추게 된다. 유레카 설정으로 인해 `DOWN`으로 내려간 서버는 더 이상 UP으로 올라오지 않게 되니 주의해야 한다.

`HealthCheckHandler`를 이용해 유레카 서버가 상태 확인시 우리가 지정한 상태로 인식할 수 있도록 구성할 수 있다.

```kotlin
@Component
class CustomHealCheckHandler : HealthCheckHandler {
    var status = InstanceInfo.InstanceStatus.UP
        private set(status) {
            synchronized(this) {
                field = status
            }
        }

    override fun getStatus(currentStatus: InstanceInfo.InstanceStatus): InstanceInfo.InstanceStatus {
        return status
    }

    fun setOutOfService() {
        status = InstanceInfo.InstanceStatus.OUT_OF_SERVICE
    }

    fun setUp() {
        status = InstanceInfo.InstanceStatus.UP
    }
}
```

`spring actuator`를 사용하는 경우 `/actuator/pause`, `/actuator/resume` 메서드를 이용할 수 있는데, PauseHandler를 구현해 내부 기능을 채운다면 쉽게 제어가능하다.

```kotlin
@Component
class CustomPauseHandler(
    private val healCheckHandler: CustomHealCheckHandler,
): PauseHandler {
    override fun pause() {
        healCheckHandler.setOutOfService()
    }

    override fun resume() {
        healCheckHandler.setUp()
    }
}

```

### 다운타임 예상시간보다 오래 지속되는현상 해결

- ecs 올라가는 시간을 늘린다. + 컨텍스트 로드 시간을 단축한다.

# 결말

### 다운타임을 문제로 삼았고 무중단 배포까지 달성했다.

- 문제를 삼지 않으면 문제가 되지 않는다.
  - 수익성은 적지만 서비스 가치를 낮출 수 있는 이슈가 아닐까.
  - 서비스 운영면에서는 비용이 많아지는 문제를 고려한다.

### 기능 추가로 빌드 시간이 늘어나는 상황

- 빌드 시간이 늘어나면 서비스 관리를 위한 자기 수복 형태를 구성하기 어려워진다.
- 빌드 시간이 지속적으로 늘어나는 상황을 대응할 필요성이 느껴진다.

- 어디서 제어하냐에 따라 관리 책임이 달라진다.
  - 애플리케이션에서도 충분히 제어할 수 있지만 데브옵스 팀에서 관리가 어려워진다.
  - 데브옵스 팀과 조율해서 어떻게 하면 잘 일 할 수 있을지 고민하며 솔루션을 도출하는게 꽤나 재밌었다.
  - 나 혼자였으면 애플리케이션에서 모두 해결했을텐데 서비스 관리 책임을 외부로 두면서 함께 관리할 수 있는 환경을 만들어가며 유관 부서와의 협업을 경험했다.
